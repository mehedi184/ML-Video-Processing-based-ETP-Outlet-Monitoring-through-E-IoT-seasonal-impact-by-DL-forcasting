# -*- coding: utf-8 -*-
"""cnn_binary_thesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QtSAqdoqoI_hiUVTGmmvkw1RxljZwc8c
"""

import os
import cv2
from PIL import Image
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.layers import Activation, Dropout, Flatten, Dense
from sklearn.preprocessing import LabelBinarizer
from keras.utils import to_categorical

from google.colab import drive
drive.mount('/content/drive')

image_directory = '/content/drive/MyDrive/CNN/data/train'
outputmodel= r"/content/drive/MyDrive/CNN/model/videoclassificationmodel"
SIZE = 180
dataset = []   
label = []

etp_on = os.listdir(image_directory+ '/on/')
for i, image_name in enumerate(etp_on):    
    
    if (image_name.split('.')[1] == 'jpg'):
        image = cv2.imread(image_directory + '/on/' + image_name)
        image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(image, 'RGB')
        image = image.resize((SIZE, SIZE))
        dataset.append(np.array(image))
        label.append(0)

etp_off = os.listdir(image_directory + '/off/')
for i, image_name in enumerate(etp_off):
    if (image_name.split('.')[1] == 'jpg'):
        image = cv2.imread(image_directory + '/off/' + image_name)
        image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(image, 'RGB')
        image = image.resize((SIZE, SIZE))
        dataset.append(np.array(image))
        label.append(1)

from sklearn.model_selection import train_test_split
from keras.utils import normalize
from tensorflow.keras.layers import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint

dataset = np.array(dataset)
label = np.array(label)

# Label binarizer
lb= LabelBinarizer()
labels= lb.fit_transform(label)

X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.25, random_state =0)

X_train = normalize(X_train, axis=1)
X_test = normalize(X_test, axis=1)

INPUT_SHAPE = (SIZE, SIZE, 3)

model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=INPUT_SHAPE))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3), kernel_initializer = 'he_uniform'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), kernel_initializer = 'he_uniform'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',             
              metrics=['accuracy'])

print(model.summary())

# #data augmentation
# batch_size=16
# train_datagen= ImageDataGenerator(
#     rotation_range=45,
#     zoom_range=0.2,
#     shear_range=0.2,
#     horizontal_flip= True,
#     vertical_flip=False,
#     rescale=1./255
# )
# validationAugmentation= ImageDataGenerator(
#     rescale=1./255
# )
# # mean= np.array([128.68,116.779,103.939],dtype="float32")
# # traininAugmentation.mean= mean
# # validationAugmentation.mean= mean
# #train_generator= train_datagen.flow_from_directory

# history= model.fit_generator(   
#     train_datagen.flow(X_train,y_train,batch_size=16),
#     steps_per_epoch= len(X_train)//16,
#     validation_data= validationAugmentation.flow(X_test,y_test),
#     validation_steps= len(X_test)//16,
#     # callbacks=[augmented_checkpoint,callback],
#     epochs=10
# )
# model.save(outputmodel,save_format="h5")

history = model.fit(X_train, 
                         y_train, 
                         batch_size = 64, 
                         verbose = 1, 
                         epochs = 50,      
                         validation_data=(X_test,y_test),
                         shuffle = False
                     )


# model.save(outputmodel)

# from keras.models import load_model
# model= load_model(r"/content/drive/MyDrive/CNN/model/videoclassificationmodel/saved_model.pb")

_, acc = model.evaluate(X_test, y_test)
print("Accuracy = ", (acc * 100.0), "%")

plt.style.use('ggplot')
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.figure(figsize=(10,6))
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
plt.figure(figsize=(10,6))
plt.plot(epochs, acc, 'y', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

n= 637 #Select the index of image to be loaded for testing
img = X_test[n]
plt.figure(figsize=(18,12))
plt.imshow(img)
plt.figure(figsize=(10,6))
input_img = np.expand_dims(img, axis=0) 
print("The prediction for this image is: ", model.predict(input_img))
print("The actual label for this image is: ", y_test[n])
# 0 for 'on'
# 1 for 'off'

from sklearn.metrics import confusion_matrix

mythreshold=0.077
y_pred = (model.predict(X_test)>= mythreshold).astype(int)
cm=confusion_matrix(y_test, y_pred)  
print(cm)

from sklearn.metrics import roc_curve

y_preds = model.predict(X_test).ravel()
fpr, tpr, thresholds = roc_curve(y_test, y_preds)
plt.figure(1) 
plt.figure(figsize=(10,6)) 
plt.plot([0, 1], [0, 1], 'y--') 
plt.plot(fpr, tpr, marker='.') 
plt.xlabel('False positive rate') 
plt.ylabel('True positive rate') 
plt.title('ROC curve') 
plt.show()

i = np.arange(len(tpr)) 
roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})
ideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  
print("Ideal threshold is: ", ideal_roc_thresh['thresholds'])

from sklearn.metrics import auc
auc_value = auc(fpr, tpr)
print("Area under curve: ", auc_value)

import pickle
from keras.models import load_model
from collections import deque
from google.colab.patches import cv2_imshow

lbinarizer= open(r"/content/drive/MyDrive/CNN/model/lbinarizer.pickle","wb")
lbinarizer.write(pickle.dumps(label))
lbinarizer.close()

model= load_model(r"/content/drive/MyDrive/CNN/model/videoclassificationmodel")
lb= pickle.loads(open(r"/content/drive/MyDrive/CNN/model/lbinarizer.pickle","rb").read())
outputvideo=r"/content/drive/MyDrive/CNN/video/output/output.mp4"
#mean=np.array([123.68,116.779,103.939][::1],dtype="float32")
Queue= deque(maxlen= 128)

from google.colab.patches import cv2_imshow
capture_video= cv2.VideoCapture(r"/content/drive/MyDrive/CNN/video/input/test.mp4")
writer= None
(Width,Height)=(None, None)
while True:
  (taken, frame)= capture_video.read()
  if not taken:
    break
  if Width is None or Height is None:
    (Width,Height)= frame.shape[:2]

  output= frame.copy()
  frame= cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)
  frame= cv2.resize(frame, (SIZE, SIZE)).astype("float32")
 # frame-=mean
  prediction=model.predict(np.expand_dims(frame, axis=0))[0]
  Queue.append(prediction)  
  results= np.array(Queue).mean(axis=0)
  j=np.argmax(results)
  l= lb.classes_[j]
  text= "VERDICT : {}".format(l)
  cv2.putText(output, text, (45, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (0,255,0),5)

  if writer is None:
    fourcc= cv2.VideoWriter_fourcc(*"MJPG")
    writer= cv2.VideoWriter(outputvideo, fourcc, 30, (Width,Height),True)

  writer.write(output)
  cv2_imshow(output)
  key= cv2.waitKey(1) & 0xFF
  if key==ord("q"):
    break

writer.release()
capture_video.release()